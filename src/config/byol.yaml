# Model wrapper configuration
__wrapper__: "models.training_wrappers.BYOL"

# Model configuration
model:
  backbone:
    _name_: "models.backbones.VGGish"
    _kwargs_:
      proj_dim: 512
      channels: [128, 128, 256, 512]
  
  projection_head:
    _name_: "models.backbones.MLP"
    _kwargs_:
      in_features: 512
      out_features: 64
      hidden_features: [512]
      activation: "relu"
      use_batch_norm: true
      dropout: 0.0
      bias: true

  predictor_head:
    _name_: "models.backbones.MLP"
    _kwargs_:
      in_features: 64
      out_features: 64
      hidden_features: [256, 128]
      activation: "relu"
      use_batch_norm: true
      dropout: 0.0
      bias: true

# Loss function configuration
loss:
  _name_: torch.nn.functional.mse_loss

# Optimizer configuration
optimizer:
  _name_: "torch.optim.Adam"
  _kwargs_:
    lr: 0.0001

# Scheduler configuration (optional)
scheduler: null

# EMA configuration for BYOL
ema:
  beta: 0.996
  update_after_step: 0
  update_every: 1

# Dataset configuration
dataset:
  train:
    _name_: "data.dataset.Giantsteps"
    _kwargs_:
      audio_dir: "data/giantsteps/audio"
      metadata_path: "data/giantsteps/metadata.json"
      sample_rate: 16000
      mono: true
      labels_: true
      processors:
        - _name_: "data.dataset.MultiView"
          _kwargs_:
            view_samples: 47999
            strategy: "random_view"
            keys: ["audio"]
        - _name_: "data.dataset.Truncate"
          _kwargs_:
            n_samples: 47999
            keys: ["audio"]
        - _name_: "data.dataset.MelSpectrogram"
          _kwargs_:
            sample_rate: 16000
            n_fft: 400
            hop_length: 160
            n_mels: 128
            f_min: 50
            f_max: 8000
            win_length: null
            power: 2.0
            keys: ["view_1", "view_2", "audio"]
  
  val: 
    _name_: "data.dataset.Giantsteps"
    _kwargs_:
      audio_dir: "data/giantsteps/audio"
      metadata_path: "data/giantsteps/metadata.json"
      sample_rate: 16000
      mono: true
      labels_: True
      processors:
        - _name_: "data.dataset.MultiView"
          _kwargs_:
            view_samples: 47999
            strategy: "random_view"
            keys: ["audio"]
        
        - _name_: "data.dataset.Truncate"
          _kwargs_:
            n_samples: 47999
            keys: ["audio"]
        - _name_: "data.dataset.MelSpectrogram"
          _kwargs_:
            sample_rate: 16000
            n_fft: 400
            hop_length: 160
            n_mels: 128
            f_min: 50
            f_max: 8000
            win_length: null
            power: 2.0
            keys: ["view_1", "view_2", "audio"]

  test: null
  
dataloader:
  train:
    batch_size: 32
    shuffle: true
    num_workers: 8
    collate_fn:
      _name_: "data.collate.multiview_collate"
  val:
    batch_size: 32
    shuffle: false
    num_workers: 8
    collate_fn:
      _name_: "data.collate.multiview_collate"
  test: null

# Trainer configuration
trainer:
  max_epochs: 1000
  devices: [2]
  accelerator: "gpu"
  precision: "16-mixed"
  log_every_n_steps: 100
  check_val_every_n_epoch: 1
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  deterministic: true
  num_sanity_val_steps: 0

# Logger configuration
logger:
  _name_: "lightning.pytorch.loggers.WandbLogger"
  _kwargs_:
    project: "music-ssl-ismir"

# Callbacks configuration
callbacks:
  model_summary:
    _name_: "lightning.pytorch.callbacks.RichModelSummary"
    _kwargs_:
      max_depth: 2

  model_checkpoint:
    _name_: "lightning.pytorch.callbacks.ModelCheckpoint"
    _kwargs_:
      save_last: true
      monitor: "loss"
      mode: "min"
      save_top_k: -1
      every_n_epochs: 30
  
  embedding_viz:
    _name_: "callbacks.viz2d.Embedding2DVisualizationCallback"
    _kwargs_:
      every_n_epochs: 10
      reduction_method: "tsne"
      tsne_perplexity: 30.0
      umap_n_neighbors: 15
      umap_min_dist: 0.1

  linear_probe:
    _name_: "callbacks.viz2d.LinearProbeCallback"
    _kwargs_:
      model_type: "mlp"
      hidden_layer_sizes: []
      activation: "relu"
      solver: "adam"
      max_iter: 5000
      validation_fraction: 0
      every_n_epochs: 10

  save_embeddings:
    _name_: "callbacks.viz2d.SaveEmbeddingsCallback"
    _kwargs_:
      every_n_epochs: 30
      save_dir: "data/embeddings/byol_embeddings"

# Strategy configuration
strategy: "auto"

# Checkpoint path (optional)
ckpt_path: null
